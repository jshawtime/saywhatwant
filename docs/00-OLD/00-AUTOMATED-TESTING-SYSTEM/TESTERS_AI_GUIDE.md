# Testers.ai Integration Guide

## ğŸ¤– What is Testers.ai?

**Testers.ai** is an AI-powered testing platform specifically designed to work with Cursor AI. It provides:

- **Automatic test generation** from your code
- **Auto-fix capabilities** for failing tests
- **Watch mode** - runs tests on every code change
- **Seamless Cursor integration** - no complex MCP setup needed
- **Full-stack testing** - UI, API, and integration tests

## ğŸ†š Testers.ai vs MCP

| Feature | Testers.ai | MCP (Puppeteer) |
|---------|-----------|-----------------|
| **Setup** | Simple (1 command) | Manual configuration |
| **Test Generation** | Built-in AI | Via Cursor prompts |
| **Auto-Fix** | Automatic | Via Cursor analysis |
| **Watch Mode** | Built-in | Manual setup |
| **Learning Curve** | Low | Medium |
| **Cost** | Freemium | Free |
| **Cursor Integration** | Native | Via MCP protocol |

**Recommendation**: 
- **Start with Testers.ai** if you want quick setup and automatic features
- **Use MCP** if you want more control and customization
- **Use both** - They complement each other!

## ğŸš€ Quick Start

### Installation

```bash
# Global installation (recommended)
npm install -g testers-ai

# Or project-local
cd /Users/pbmacstudiomain/devrepo/SAYWHATWANTv1/saywhatwant
npm install --save-dev testers-ai
```

### Initialize in Your Project

```bash
cd /Users/pbmacstudiomain/devrepo/SAYWHATWANTv1/saywhatwant
testers-ai init
```

This will:
1. Analyze your project structure
2. Detect your testing framework (Playwright)
3. Create a `testers.config.json` file
4. Set up integration with Cursor

### Verify Installation

```bash
testers-ai --version
```

## ğŸ’» Usage

### In Cursor AI Chat

Once installed, you can use Testers.ai directly in Cursor:

#### Run Tests
```
@testers run all tests
@testers run tests for video player
@testers run smoke tests
```

#### Generate Tests
```
@testers generate tests for the CommentsStream component
@testers create test for user color selection
@testers generate API tests for the comments worker
```

#### Fix Failing Tests
```
@testers fix failing tests
@testers analyze test failures and propose fixes
@testers fix the video toggle test
```

#### Watch Mode
```
@testers watch
@testers start watching for changes
```

This will:
- Monitor your files for changes
- Automatically run relevant tests
- Report results in real-time
- Auto-fix issues when possible

### Command Line

You can also use Testers.ai directly from the command line:

```bash
# Run all tests
testers-ai test

# Run specific tests
testers-ai test --file video-player.spec.ts

# Generate tests
testers-ai generate --component CommentsStream

# Fix failures
testers-ai fix

# Watch mode
testers-ai watch

# Analyze coverage
testers-ai coverage
```

## ğŸ¯ Configuration

### testers.config.json

After running `testers-ai init`, you'll have a config file:

```json
{
  "framework": "playwright",
  "testDir": "./tests",
  "sourceDir": "./",
  "coverageThreshold": 80,
  "autoFix": true,
  "watchMode": {
    "enabled": true,
    "debounce": 1000
  },
  "generation": {
    "style": "user-flow",
    "includeEdgeCases": true
  },
  "cursor": {
    "integration": "enabled"
  }
}
```

### Customize Settings

```json
{
  "framework": "playwright",
  "testDir": "./tests",
  "sourceDir": "./",
  
  // Coverage settings
  "coverageThreshold": 80,
  "coverageReports": ["html", "json"],
  
  // Auto-fix settings
  "autoFix": {
    "enabled": true,
    "confidence": 0.8,
    "maxAttempts": 3
  },
  
  // Watch mode
  "watchMode": {
    "enabled": true,
    "debounce": 1000,
    "runOnSave": true
  },
  
  // Test generation
  "generation": {
    "style": "user-flow",
    "includeEdgeCases": true,
    "includeAccessibility": true,
    "includePerformance": false
  },
  
  // Browser settings
  "browser": {
    "type": "chromium",
    "headless": true,
    "viewport": {
      "width": 1920,
      "height": 1080
    }
  },
  
  // Cursor integration
  "cursor": {
    "integration": "enabled",
    "autoOpenReports": true
  }
}
```

## ğŸ”„ Workflow Examples

### Workflow 1: Feature Development + Testing

```
# 1. Start watch mode
@testers watch

# 2. Develop your feature (Testers.ai monitors in background)
[Make code changes...]

# 3. Tests run automatically on save
[Testers.ai runs relevant tests]

# 4. If tests fail, auto-fix attempts
[Testers.ai proposes fixes]

# 5. Review and accept fixes
@testers show last fixes
```

### Workflow 2: Test Generation for New Feature

```
# 1. Create your component
[Create VideoPlayer.tsx]

# 2. Ask Testers.ai to generate tests
@testers generate comprehensive tests for VideoPlayer component

# 3. Review generated tests
[Review tests/video-player.spec.ts]

# 4. Run tests
@testers run video player tests

# 5. Refine if needed
@testers add edge case tests for video loading failures
```

### Workflow 3: Bug Fixing

```
# 1. Test fails on CI/CD
[GitHub Actions reports failure]

# 2. Ask Testers.ai to analyze
@testers analyze the failing video toggle test

# 3. Get root cause analysis
[Testers.ai identifies the issue]

# 4. Auto-fix
@testers fix the video toggle issue

# 5. Verify
@testers run video player tests
```

### Workflow 4: Refactoring

```
# 1. Before refactoring
@testers run all tests
[Baseline: all tests pass]

# 2. Refactor your code
[Change color system implementation]

# 3. Testers.ai detects changes
[Watch mode triggers relevant tests]

# 4. If tests fail
@testers fix broken tests after refactoring

# 5. Verify coverage maintained
@testers check coverage
```

## ğŸ“ Advanced Features

### 1. Smart Test Generation

Testers.ai analyzes your code to generate intelligent tests:

```
@testers generate tests for CommentsStream with focus on:
- User interactions
- Error handling
- Edge cases
- Accessibility
- Performance
```

Result: Comprehensive test suite covering all aspects

### 2. Visual Regression Testing

```
@testers add visual regression tests for homepage
```

Testers.ai will:
- Take baseline screenshots
- Compare on subsequent runs
- Highlight visual differences
- Auto-update baselines when approved

### 3. API Testing

```
@testers generate API tests for comments worker
```

Tests:
- All endpoints
- Request/response validation
- Error handling
- Rate limiting
- Authentication

### 4. Accessibility Testing

```
@testers run accessibility audit
```

Checks:
- WCAG compliance
- Keyboard navigation
- Screen reader compatibility
- Color contrast
- ARIA labels

### 5. Performance Testing

```
@testers add performance tests for video player
```

Measures:
- Load time
- Interaction responsiveness
- Memory usage
- CPU usage
- Network requests

## ğŸ“Š Reporting

### Test Results

Testers.ai provides rich reports:

```bash
# Generate report
testers-ai report

# Open in browser
testers-ai report --open
```

Report includes:
- âœ… Passed tests
- âŒ Failed tests
- âš ï¸ Flaky tests
- ğŸ“Š Coverage metrics
- ğŸ¯ Performance metrics
- ğŸ”§ Auto-fix attempts

### Integration with Cursor

Results appear directly in Cursor:
- Inline test status
- Failure reasons
- Suggested fixes
- Quick actions (run, debug, fix)

## ğŸ”§ Troubleshooting

### Testers.ai Not Working in Cursor

**Issue**: `@testers` commands not recognized

**Solutions**:
1. Verify installation:
   ```bash
   testers-ai --version
   ```

2. Reinitialize:
   ```bash
   testers-ai init --force
   ```

3. Restart Cursor completely

4. Check Cursor logs:
   - Help â†’ Toggle Developer Tools â†’ Console
   - Look for Testers.ai errors

### Auto-Fix Not Working

**Issue**: Tests fail but no fixes proposed

**Solutions**:
1. Check auto-fix is enabled in config:
   ```json
   {
     "autoFix": {
       "enabled": true,
       "confidence": 0.8
     }
   }
   ```

2. Lower confidence threshold:
   ```json
   {
     "autoFix": {
       "confidence": 0.6
     }
   }
   ```

3. Try manual fix:
   ```
   @testers fix this test manually
   ```

### Watch Mode Not Triggering

**Issue**: Changes don't trigger tests

**Solutions**:
1. Check watch mode enabled:
   ```json
   {
     "watchMode": {
       "enabled": true,
       "runOnSave": true
     }
   }
   ```

2. Increase debounce:
   ```json
   {
     "watchMode": {
       "debounce": 2000
     }
   }
   ```

3. Restart watch mode:
   ```
   @testers stop watching
   @testers watch
   ```

### Tests Timeout

**Issue**: Tests timeout in watch mode

**Solution**: Increase timeout in config:
```json
{
  "timeout": 120000
}
```

## ğŸ’° Pricing & Plans

Testers.ai offers different tiers:

### Free Tier
- 100 test runs/month
- Basic test generation
- Auto-fix (limited)
- Community support

### Pro Tier ($29/month)
- Unlimited test runs
- Advanced test generation
- Full auto-fix
- Watch mode
- Priority support

### Team Tier ($99/month)
- All Pro features
- Multiple team members
- Shared test libraries
- Analytics dashboard
- Dedicated support

**Note**: Check https://testers.ai/pricing for current pricing

## ğŸ†š When to Use What?

### Use Testers.ai When:
- âœ… You want quick setup (< 5 minutes)
- âœ… You want automatic test generation
- âœ… You want auto-fix on failures
- âœ… You want watch mode
- âœ… You're building features rapidly
- âœ… You want less manual testing

### Use MCP (Puppeteer) When:
- âœ… You want full control
- âœ… You want custom automation scripts
- âœ… You need advanced browser control
- âœ… You want zero recurring costs
- âœ… You need integration with other tools

### Use Both When:
- âœ… You want the best of both worlds
- âœ… Development: Testers.ai for speed
- âœ… Production: MCP for custom workflows
- âœ… CI/CD: Both for comprehensive coverage

## ğŸ“š Resources

### Official Documentation
- Website: https://testers.ai
- Docs: https://docs.testers.ai
- Blog: https://testers.ai/blog

### Community
- Discord: https://discord.gg/testers-ai
- GitHub: https://github.com/testers-ai
- Twitter: @testers_ai

### Tutorials
- Getting Started: https://testers.ai/tutorial
- Advanced Features: https://testers.ai/advanced
- Integration Guide: https://testers.ai/cursor

## âœ¨ Tips & Tricks

### 1. Combine with Playwright
```
# Use Playwright for test execution
# Use Testers.ai for generation and fixing
npm run test:ui    # Playwright UI
@testers fix       # Testers.ai auto-fix
```

### 2. Use Natural Language
```
@testers create a test that:
- Opens the app
- Toggles the video
- Changes the user color
- Submits a comment
- Verifies everything works
```

### 3. Iterative Refinement
```
@testers generate basic tests for VideoPlayer
# Review results
@testers add edge cases to video player tests
# Review again
@testers add accessibility tests
# Perfect!
```

### 4. Context-Aware Generation
```
@testers analyze the CommentsStream component and generate tests based on:
- User stories in comments
- Props and state
- Event handlers
- Edge cases from code
```

### 5. Smart Fixing
```
@testers fix this test but:
- Don't change the test logic
- Only fix the selectors
- Maintain the same test coverage
```

## ğŸ¯ Your Testers.ai Workflow

### Daily Development
1. Start watch mode: `@testers watch`
2. Code your features
3. Tests run automatically
4. Failures auto-fix
5. Focus on coding! ğŸ‰

### New Feature
1. Build the feature
2. `@testers generate tests for [feature]`
3. Review and refine tests
4. Run tests
5. Ship it! ğŸš€

### Bug Fix
1. Reproduce the bug
2. `@testers create test that reproduces [bug]`
3. Fix the bug
4. Test passes
5. Done! âœ…

### Refactoring
1. Ensure tests pass
2. Refactor code
3. Testers.ai watches and tests
4. Auto-fixes any broken tests
5. Verify coverage maintained
6. Merge! ğŸŠ

---

**Next Steps:**
1. Install Testers.ai: `npm install -g testers-ai`
2. Initialize: `testers-ai init`
3. Try it: `@testers run all tests`
4. Start watching: `@testers watch`
5. Focus on building features! ğŸš€

