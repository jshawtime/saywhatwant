# 169: Durable Objects Migration

**Date**: 2025-11-01  
**Status**: PHASE 2 COMPLETE - Worker deployed, PM2 bot ready, frontend next

---

## ‚úÖ Progress Update

### Phase 1: Deploy DO Worker ‚úÖ COMPLETE
- **Worker URL**: `https://saywhatwant-do-worker.bootloaders.workers.dev`
- All endpoints tested and working:
  - ‚úÖ POST `/api/comments` - Message storage (clean ID format)
  - ‚úÖ GET `/api/comments?since=X` - Retrieve messages
  - ‚úÖ GET `/api/queue/pending` - PM2 polling
  - ‚úÖ POST `/api/queue/claim` - Claim message
  - ‚úÖ POST `/api/queue/complete` - Mark complete
- **Stress test**: 14 messages posted, all stored correctly
- **State transitions**: `pending ‚Üí processing ‚Üí complete` verified

### Phase 2: Rewrite PM2 Bot ‚úÖ COMPLETE
- **New bot**: `AI-Bot-Deploy/src/index-do-simple.ts`
- Compiled successfully, ready to run
- **Start script**: `./start-do-bot.sh`
- **Code reduction**: ~70% less code (no self-healing needed)
- Uses new DO endpoint: `https://saywhatwant-do-worker.bootloaders.workers.dev`

### Phase 3: Update Frontend üîÑ NEXT
- Update `API_URL` in `CommentsStream.tsx`
- Test polling and message display
- Verify no regressions

### Phase 4: Stress Test & Cutover
- Run 30-tab stress test
- Verify 30/30 success rate
- Deploy to production

---

## ‚ö†Ô∏è CRITICAL: No Data Preservation Needed

**This project is in stealth development with ZERO users. We can completely nuke all KV data without consequence.**

This means:
- No migration scripts needed
- No backward compatibility required
- Clean slate implementation
- Delete `recent:comments` cache entirely
- Delete all `comment:{id}` entries
- Start fresh with Durable Objects

---

## Executive Summary: Why Durable Objects

### What We're Building
A single Durable Object instance (`"message-queue"`) that holds all message state in-memory with automatic persistence.

### Key Benefits
- **Strong consistency** - Single-threaded execution eliminates all race conditions
- **Atomic operations** - No cache sync issues, ever
- **High performance** - In-memory operations (~2ms per request), handles 500+ req/sec
- **Low cost** - $1.70 per 1M messages (first ~140K/month free with base plan)
- **Simple architecture** - Single source of truth, no distributed state

### How It Works
```
Request ‚Üí Worker routes to DO ‚Üí DO updates in-memory state ‚Üí 
DO persists to storage (async) ‚Üí Response
```

All operations serialized through single instance = guaranteed consistency.

### Cost Structure
- **Requests**: $0.15 per 1M (first 1M free/month)
- **Storage writes**: $0.20 per 1M (first 1M free/month)
- **Storage size**: $0.36/GB-month (first 1GB free)
- **Field count doesn't matter** - pay per operation, not per key
- **Negligible storage cost** - 200 messages √ó 1KB = $0.00007/month

### Performance
- **Capacity**: ~500 writes/sec, ~2000 reads/sec per DO
- **Latency**: 2-5ms per request
- **At 100 msg/sec**: 20% DO capacity, plenty of headroom
- **Cold start**: ~20ms (stays warm with activity)

### Frontend Changes
- None required - same `?since=timestamp` polling API
- DO state always consistent (no missed messages)
- Regressive polling (5s ‚Üí 30s) continues to work
- Optional future: WebSocket support for real-time push

---

## What Are Durable Objects?

### Conceptual Model

**Durable Objects = Actor Model + Persistent State**

Think of a Durable Object as a **single-threaded microservice instance** with:
- **Persistent in-memory state** (survives restarts via automatic storage)
- **Strong consistency** (single instance = no race conditions)
- **Geographic locality** (runs close to users)
- **Automatic persistence** (state writes to disk transparently)

### Key Characteristics

1. **Single-Threaded Execution**
   - All requests to the same DO instance are serialized
   - No locking needed - sequential by design
   - Simplifies state management dramatically

2. **Unique Instance Per ID**
   - Each DO has a unique ID (e.g., "message-queue")
   - Cloudflare routes all requests with that ID to the same instance
   - Instance stays warm as long as there's activity

3. **Persistent Storage**
   - `state.storage` API (like SQLite in memory)
   - Automatic durability - writes are persisted
   - Fast reads (in-memory) + durable writes (disk)

4. **Cold Start**
   - ~20ms startup if instance not running
   - Stays warm for 30s+ after last request
   - Our use case: continuous activity = stays warm

---

## How Durable Objects Work: Message Flow Example

### Current System (KV + Cache)
```
Frontend POST ‚Üí Worker ‚Üí Write message to KV
                      ‚Üí Read cache from KV
                      ‚Üí Update cache array
                      ‚Üí Write cache to KV
                      ‚Üí Return

Problem: Non-atomic, cache can become stale
```

### Durable Objects System
```
Frontend POST ‚Üí Worker ‚Üí Route to DO instance "message-queue"
                      ‚Üí DO.fetch() receives request
                      ‚Üí DO updates in-memory state
                      ‚Üí DO persists to state.storage
                      ‚Üí Return

Benefit: Atomic, always consistent
```

---

## Message Flow with Durable Objects

### 1. Human Posts Message

```
Frontend: POST /api/comments
  ‚Üì
Worker: Determines DO ID (e.g., "global-queue")
  ‚Üì
Worker: Routes to DO instance
  ‚Üì
DO: this.messages = await state.storage.get('messages') || []
DO: Generate messageId (pure random: "abc123xyz")
DO: Create message object:
    {
      id: "abc123xyz",
      timestamp: Date.now(),
      text: "Why is space black?",
      username: "Human",
      color: "169080199",
      messageType: "human",
      replyTo: null,
      botParams: {
        status: "pending",
        priority: 5,
        entity: "fear-and-loathing"
      }
    }
DO: this.messages.unshift(message)
DO: this.messages = this.messages.slice(0, 200)  // Keep last 200
DO: await state.storage.put('messages', this.messages)
  ‚Üì
Return: { id, timestamp }
```

**Single operation, fully atomic. No cache sync issues.**

---

### 2. Frontend Polls for Messages

```
Frontend: GET /api/comments?since=1762025642000
  ‚Üì
Worker: Routes to DO instance "global-queue"
  ‚Üì
DO: messages = await state.storage.get('messages') || []
DO: Filter messages where timestamp > since
  ‚Üì
Return: filtered messages
```

**Reads from in-memory state (fast) with guaranteed consistency.**

---

### 3. PM2 Bot Polls for Pending

```
PM2: GET /api/queue/pending
  ‚Üì
Worker: Routes to DO instance "global-queue"
  ‚Üì
DO: messages = await state.storage.get('messages') || []
DO: pending = messages.filter(m => m.botParams.status === 'pending')
DO: Sort by priority & timestamp
  ‚Üì
Return: pending[0...10]
```

**No KV reads per message. No verification needed. State is authoritative.**

---

### 4. PM2 Bot Claims Message

```
PM2: POST /api/queue/claim { messageId, workerId }
  ‚Üì
Worker: Routes to DO instance "global-queue"
  ‚Üì
DO: messages = await state.storage.get('messages') || []
DO: message = messages.find(m => m.id === messageId)
DO: if (message.botParams.status !== 'pending') return 409
DO: message.botParams.status = 'processing'
DO: message.botParams.claimedBy = workerId
DO: message.botParams.claimedAt = Date.now()
DO: await state.storage.put('messages', messages)
  ‚Üì
Return: { success: true, message }
```

**Atomic claim. Impossible for two PM2 instances to claim same message.**

---

### 5. PM2 Posts AI Response

```
PM2: POST /api/comments (AI reply)
  ‚Üì
Worker: Routes to DO instance "global-queue"
  ‚Üì
DO: messages = await state.storage.get('messages') || []
DO: Create AI message with replyTo: humanMessageId
DO: messages.unshift(aiMessage)
DO: messages = messages.slice(0, 200)
DO: await state.storage.put('messages', messages)
  ‚Üì
Return: { id, timestamp }
```

**Same flow as human post. Consistent.**

---

### 6. PM2 Marks Complete

```
PM2: POST /api/queue/complete { messageId }
  ‚Üì
Worker: Routes to DO instance "global-queue"
  ‚Üì
DO: messages = await state.storage.get('messages') || []
DO: message = messages.find(m => m.id === messageId)
DO: if (message.botParams.status !== 'processing') return 409
DO: message.botParams.status = 'complete'
DO: message.botParams.completedAt = Date.now()
DO: await state.storage.put('messages', messages)
  ‚Üì
Return: { success: true }
```

**Atomic status update. No cache sync.**

---

## Architecture Design

### Option 1: Single Global Queue DO

**ID**: `"global-queue"`

**Pros:**
- ‚úÖ Simple - one DO instance handles everything
- ‚úÖ Strong consistency across all operations
- ‚úÖ Easy to reason about
- ‚úÖ No routing complexity

**Cons:**
- ‚ö†Ô∏è Single bottleneck (but can handle ~1000 req/sec)
- ‚ö†Ô∏è Geographic latency if users spread globally

**Verdict:** **RECOMMENDED for v1** - Our scale doesn't need sharding yet.

---

### Option 2: One DO Per Entity

**ID**: `"queue:{entity}"` (e.g., `"queue:fear-and-loathing"`)

**Pros:**
- ‚úÖ Parallel processing per entity
- ‚úÖ Scales better for many entities
- ‚úÖ Isolated failures

**Cons:**
- ‚ö†Ô∏è More complex routing logic
- ‚ö†Ô∏è Frontend needs to poll multiple DOs
- ‚ö†Ô∏è Cross-entity queries harder

**Verdict:** **OVERKILL for now** - Consider for v2 if we hit scale limits.

---

### Option 3: Hybrid (Recommended for v2+)

**Global DO** for all messages + **Entity-specific DOs** for processing queues.

Not needed now, but architecture can evolve to this.

---

## State Structure Inside DO

### In-Memory State
```javascript
class MessageQueue {
  constructor(state, env) {
    this.state = state;
    this.env = env;
    this.messages = null; // Lazy loaded
  }

  async getMessages() {
    if (!this.messages) {
      this.messages = await this.state.storage.get('messages') || [];
    }
    return this.messages;
  }

  async saveMessages() {
    await this.state.storage.put('messages', this.messages);
  }
}
```

### Storage Keys
```
'messages' ‚Üí Array of last 200 message objects
'stats'    ‚Üí { totalMessages, lastReset, etc } (optional)
```

---

## Clean Message Structure (Refactored)

```javascript
{
  id: "abc123xyz",              // Pure random, no timestamp
  timestamp: 1762025642726,      // Separate field
  text: "Why is space black?",
  username: "Human",
  color: "169080199",
  messageType: "human",          // "human" | "AI"
  replyTo: null,                 // Message ID or null
  botParams: {
    status: "pending",           // "pending" | "processing" | "complete" | "failed"
    priority: 5,
    entity: "fear-and-loathing",
    claimedBy: null,             // Worker ID when processing
    claimedAt: null,             // Timestamp
    completedAt: null            // Timestamp
  }
}
```

**Removed:**
- `processed` field (redundant - use `status === 'complete'`)
- Timestamp from ID (separate `timestamp` field)

---

## Cost Comparison: KV vs Durable Objects

### Current KV System (Per Message Roundtrip)

**Operations:**
- POST message: 2 KV writes, 1 KV read
- PM2 poll: 1 KV read + N verification reads
- Claim: 2 KV writes, 2 KV reads
- Complete: 2 KV writes, 2 KV reads
- **Total: ~9 KV operations**

**Cost:** ~$0.50 per 1M reads, ~$5 per 1M writes
- Reads: 6 √ó $0.50 = $3/1M roundtrips
- Writes: 6 √ó $5 = $30/1M roundtrips
- **Total: ~$33/1M messages**

---

### Durable Objects System

**Operations:**
- POST message: 1 DO request, 1 storage write
- PM2 poll: 1 DO request, 0 storage ops (in-memory)
- Claim: 1 DO request, 1 storage write
- Complete: 1 DO request, 1 storage write
- **Total: 4 DO requests, 3 storage writes**

**Cost:** $0.15 per 1M requests, $0.20 per 1M storage writes
- Requests: 4 √ó $0.15 = $0.60/1M roundtrips
- Storage writes: 3 √ó $0.20 = $0.60/1M roundtrips
- **Total: ~$1.20/1M messages**

**Savings: ~96% cheaper ($33 ‚Üí $1.20)**

---

## Benefits Summary

### 1. **Strong Consistency**
- No stale cache
- No KVr:3 ghost messages
- No cache sync issues

### 2. **Atomic Operations**
- No race conditions
- Guaranteed state transitions
- Claim/complete always correct

### 3. **Simpler Code**
- No cache management logic
- No self-healing verification
- Single source of truth

### 4. **Better Performance**
- In-memory reads (< 1ms)
- No per-message KV lookups
- Stays warm with activity

### 5. **Lower Cost**
- 96% cheaper than current system
- Scales better with load

### 6. **Easier Debugging**
- All state in one place
- Sequential execution = predictable
- No distributed state mysteries

---

## Migration Strategy

### Phase 1: Implement DO (No KV)
1. Create `MessageQueue` Durable Object class
2. Implement all endpoints (POST, GET, claim, complete)
3. Update Worker to route to DO instead of KV
4. **Delete all KV data** (no migration needed)
5. Deploy

### Phase 2: Clean Message Structure
1. Remove timestamp from ID generation
2. Remove `processed` field usage
3. Update frontend to handle new IDs
4. Test thoroughly

### Phase 3: Monitor & Optimize
1. Watch DO performance metrics
2. Monitor costs (should drop significantly)
3. Verify 100% success rate
4. Add WebSocket support (future)

---

## Open Questions

1. **DO ID Strategy**: Single global or entity-based?
   - **Recommendation**: Start with single global `"message-queue"`

2. **Message Retention**: Keep 200 in memory, but how long in storage?
   - **Recommendation**: Keep last 200 only, prune older

3. **Frontend Changes**: Can continue polling or upgrade to WebSockets?
   - **Recommendation**: Keep polling for v1, WebSockets for v2

4. **PM2 Changes**: Any needed?
   - **Recommendation**: Only endpoint URLs change, logic stays same

---

## Implementation Progress

### ‚úÖ Completed

**Phase 1: DO Worker Setup (DONE)**
1. ‚úÖ Created `MessageQueue.js` Durable Object class
   - 296 lines of clean, focused code
   - All endpoints implemented: POST, GET, pending, claim, complete
   - In-memory state with automatic persistence
   - Clean message structure (no timestamp in ID, no `processed` field)

2. ‚úÖ Created `saywhatwant-do-worker.js` Worker
   - 23 lines - just routes to DO
   - Routes to single "global-queue" DO instance

3. ‚úÖ Created `wrangler-do.toml` configuration
   - DO bindings configured
   - Migration setup for MessageQueue class

4. ‚úÖ Deployed to Cloudflare
   - Live at: `https://saywhatwant-do-worker.bootloaders.workers.dev`
   - Successfully tested POST and GET endpoints
   - Message storage working perfectly

**Test Results:**
```bash
# POST message
curl -X POST '.../api/comments' -d '{"text":"test",...}'
‚Üí Response: {"id":"24spd5q8ti","timestamp":1762032398376,"status":"success"}

# GET messages  
curl '.../api/comments?since=0'
‚Üí Response: [{"id":"24spd5q8ti",...,"status":"pending"}]
```

**Key Achievements:**
- Clean 10-char IDs (no timestamp prefix)
- No `processed` field (using `status` only)
- Sub-5ms response times
- Strong consistency (no cache issues)

---

### üîÑ Next Steps

**Phase 2: Test PM2 Endpoints**
1. Test `/api/queue/pending` endpoint
   ```bash
   curl 'https://saywhatwant-do-worker.bootloaders.workers.dev/api/queue/pending?limit=10'
   # Should return pending messages
   ```

2. Test `/api/queue/claim` endpoint
   ```bash
   curl -X POST '.../api/queue/claim' \
     -d '{"messageId":"24spd5q8ti","workerId":"test-worker"}'
   # Should claim message, change status to 'processing'
   ```

3. Test `/api/queue/complete` endpoint
   ```bash
   curl -X POST '.../api/queue/complete' \
     -d '{"messageId":"24spd5q8ti"}'
   # Should mark message complete
   ```

4. Verify full state transitions
   - POST ‚Üí status='pending'
   - CLAIM ‚Üí status='processing'
   - COMPLETE ‚Üí status='complete'
   - Verify each step with GET

**Phase 3: Rewrite PM2 Bot (RECOMMENDED APPROACH)**

**Decision: Rewrite vs Edit**
- ‚úÖ **REWRITE**: Create new `index-do-simple.ts` (~150 lines)
- ‚ùå **EDIT**: Modify existing `index-simple.ts` (risk of missed KV cleanup)

**Why Rewrite:**
- Current bot: 460 lines with KV logic, self-healing, cache awareness
- New bot: ~150 lines, simple polling, no verification needed
- Clean mental model, no legacy baggage
- Can test both in parallel
- Easier to understand and maintain

**Rewrite Tasks:**
1. Create `hm-server-deployment/AI-Bot-Deploy/src/index-do-simple.ts`
2. Remove ALL KV-related code:
   - No cache verification reads
   - No self-healing polling of cache
   - No `pendingAIResponses` tracking
   - Trust DO state completely
3. Simplify polling logic:
   - GET `/api/queue/pending` ‚Üí returns ready-to-process messages
   - POST `/api/queue/claim` ‚Üí atomically claims
   - No verification needed (DO handles consistency)
4. Update `package.json` scripts to use new file
5. Test with PM2 locally
6. Run stress test (14 messages)

**Phase 4: Stress Testing**
1. Post 14 test messages (different entities)
   ```bash
   for i in {1..14}; do
     curl -X POST '.../api/comments' -d '{...}'
   done
   ```

2. Verify PM2 bot processes all 14
   - Watch PM2 logs: `pm2 logs ai-bot-simple`
   - Expect: No KVr:3 ghost messages
   - Expect: 14/14 AI replies

3. Check for race conditions
   - All claims successful?
   - No duplicate processing?
   - All completions successful?

4. Verify frontend sees all messages
   - Poll `.../api/comments?since=0`
   - Should see 14 human + 14 AI = 28 messages

**Phase 5: Frontend Migration**
1. Update frontend API URL
   - Current: `https://sww-comments.bootloaders.workers.dev`
   - New: `https://saywhatwant-do-worker.bootloaders.workers.dev`
   
2. Files to update:
   - `components/CommentsStream.tsx` - API_BASE_URL
   - Any other API calls to worker

3. Test frontend locally
   - Post message ‚Üí should see it appear
   - Refresh ‚Üí should persist
   - Multiple tabs ‚Üí should sync

4. Deploy frontend to Cloudflare Pages
   - Push to git main
   - Auto-deploys

**Phase 6: PM2 Bot Migration**
1. Update PM2 bot API URL
   - `hm-server-deployment/AI-Bot-Deploy/src/index-do-simple.ts`
   - Change `API_URL` constant

2. Build new bot:
   ```bash
   cd hm-server-deployment/AI-Bot-Deploy
   npm run build
   ```

3. Restart PM2 with new code:
   ```bash
   pm2 restart ai-bot-simple
   ```

4. Monitor logs:
   ```bash
   pm2 logs ai-bot-simple --lines 100
   ```

5. Expected log changes:
   - No more `[KVr:3 KVw:1]` messages
   - Should see `[KVr:1 KVw:0]` equivalent
   - No self-heal spam
   - Clean claim/complete cycle

**Phase 7: Production Cutover**
1. Verify 100% success rate
   - Run 30/30 stress test
   - All messages get AI replies
   - No failures

2. Monitor for 24 hours
   - Check error rates
   - Check response times
   - Check costs (should drop 96%)

3. Clean up old system:
   - Delete `workers/comments-worker.js` (old KV worker)
   - Delete KV namespace binding
   - Remove KV from `wrangler.toml`
   - Delete all KV data

4. Update documentation:
   - Mark KV system as deprecated
   - Update architecture diagrams
   - Update README summaries

**Phase 8: Optimization & Monitoring**
1. Add DO metrics logging
   - Track request counts
   - Track response times
   - Track storage operations

2. Add custom domain
   - Set up `api.saywhatwant.app`
   - Route to DO worker
   - Update frontend to use clean URL

3. Consider WebSocket support (future)
   - DO supports WebSockets natively
   - Could eliminate polling entirely
   - Real-time push updates

4. Monitor costs
   - Should see 96% reduction
   - Track DO request metrics
   - Verify storage usage

---

## Files Created

```
saywhatwant/
  workers/
    saywhatwant-do-worker.js          ‚Üê New worker (23 lines)
    durable-objects/
      MessageQueue.js                  ‚Üê DO class (296 lines)
  wrangler-do.toml                     ‚Üê DO config
  deploy-do-worker.sh                  ‚Üê Deployment script

Next to create:
  hm-server-deployment/AI-Bot-Deploy/src/
    index-do-simple.ts                 ‚Üê New PM2 bot (~150 lines)
```

---

## Testing Checklist

**Before PM2 Migration:**
- [ ] POST message works
- [ ] GET messages works
- [ ] GET pending works
- [ ] CLAIM message works
- [ ] COMPLETE message works
- [ ] State transitions work (pending ‚Üí processing ‚Üí complete)
- [ ] Multiple messages don't interfere
- [ ] Message IDs are clean (no timestamp prefix)

**After PM2 Migration:**
- [ ] Bot polls successfully
- [ ] Bot claims messages
- [ ] Bot generates AI responses
- [ ] Bot completes messages
- [ ] 14/14 stress test passes
- [ ] No ghost messages (KVr:1 always)
- [ ] No race conditions
- [ ] Frontend sees all messages

**After Frontend Migration:**
- [ ] User posts message ‚Üí sees it appear
- [ ] User sees AI replies
- [ ] Multiple tabs sync
- [ ] Page refresh shows all messages
- [ ] No missed messages

**Production Validation:**
- [ ] 30/30 stress test passes
- [ ] Cost reduction visible (96%)
- [ ] Response times < 5ms average
- [ ] No errors in 24 hours
- [ ] Old KV worker can be deleted

---

## Success Criteria

- ‚úÖ 100% message delivery rate (vs current 64%)
- ‚úÖ No KVr:3 ghost messages
- ‚úÖ < 50ms average DO response time
- ‚úÖ ~$1/1M messages cost (vs $33)
- ‚úÖ Zero cache sync issues
- ‚úÖ Cleaner, simpler codebase

---

**This migration should take ~2-4 hours of focused work and eliminate the entire class of cache consistency bugs.**

